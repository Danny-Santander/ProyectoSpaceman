{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYzkKBRrUUAC2xham9WYJi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install gdown psycopg2 pandas"
      ],
      "metadata": {
        "id": "OBXtPQ59hmJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import os\n",
        "\n",
        "# URL de la carpeta compartida\n",
        "file_url = \"https://drive.google.com/drive/folders/17a0kvZD1ZfRPyMCgrNlr4vCCdqN9djCv\"\n",
        "output_folder = \"Downloads/Spaceman\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Descargar archivos usando gdown\n",
        "def download_from_folder(file_url, output_folder):\n",
        "    print(\"Descargando archivos de la carpeta...\")\n",
        "# Convertir la URL de la carpeta a formato descargable\n",
        "    gdown.download_folder(file_url, output=output_folder, quiet=False)\n",
        "\n",
        "download_from_folder(file_url, output_folder)\n",
        "print(f\"Descarga completa. Archivos guardados en: {output_folder}\")\n"
      ],
      "metadata": {
        "id": "ay7Miqj3htIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psycopg2\n",
        "import pandas as pd\n",
        "\n",
        "# Configuración de conexión a PostgreSQL\n",
        "db_host = os.getenv(\"DB_HOST\", \"localhost\")\n",
        "db_name = os.getenv(\"DB_NAME\", \"spaceman\")\n",
        "db_user = os.getenv(\"DB_USER\", \"postgres\")\n",
        "db_password = os.getenv(\"DB_PASSWORD\", \"dba\")\n",
        "db_port = os.getenv(\"DB_PORT\", \"5432\")\n",
        "\n",
        "# Ruta local donde se encuentran los archivos\n",
        "local_folder = r\"C:\\Users\\dsantander\\Downloads\\Spaceman\"\n",
        "\n",
        "# Inferir el tipo de datos de PostgreSQL basado en pandas\n",
        "def infer_postgresql_type(dtype, max_value=None, min_value=None):\n",
        "    if pd.api.types.is_integer_dtype(dtype):\n",
        "        if max_value and (max_value > 2_147_483_647 or min_value < -2_147_483_648):\n",
        "            return \"BIGINT\"\n",
        "        return \"INTEGER\"\n",
        "    elif pd.api.types.is_float_dtype(dtype):\n",
        "        return \"REAL\"\n",
        "    elif pd.api.types.is_bool_dtype(dtype):\n",
        "        return \"BOOLEAN\"\n",
        "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
        "        return \"TIMESTAMP\"\n",
        "    else:\n",
        "        return \"TEXT\"\n",
        "\n",
        "# Crear tabla e insertar registros en PostgreSQL\n",
        "def process_file(file_path, delimiter=\";\"):\n",
        "    conn = None\n",
        "    cur = None\n",
        "    try:\n",
        "        # Conexión a la base de datos\n",
        "        conn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password, port=db_port)\n",
        "        cur = conn.cursor()\n",
        "\n",
        "        # Leer el archivo con pandas, probando diferentes codificaciones\n",
        "        encodings_to_try = ['utf-8', 'latin-1', 'ISO-8859-1']\n",
        "        df = None\n",
        "        for encoding in encodings_to_try:\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, delimiter=delimiter, low_memory=False, on_bad_lines='skip', encoding=encoding)\n",
        "                break  # Si se lee correctamente, salimos del bucle\n",
        "            except UnicodeDecodeError:\n",
        "                continue  # Intenta con la siguiente codificación\n",
        "\n",
        "        if df is None:\n",
        "            print(f\"No se pudo leer el archivo {file_path} con las codificaciones probadas.\")\n",
        "            return\n",
        "\n",
        "        # Validar que el DataFrame no esté vacío\n",
        "        if df.empty:\n",
        "            print(f\"El archivo {file_path} está vacío o no tiene datos válidos.\")\n",
        "            return\n",
        "\n",
        "        # Inferir tipos de columnas y construir la sentencia CREATE TABLE\n",
        "        table_name = \"tickets\"  # Nombre de la tabla basada en el nombre requerido\n",
        "        columns_with_types = []\n",
        "        for col in df.columns:\n",
        "            max_value, min_value = None, None\n",
        "            if pd.api.types.is_numeric_dtype(df[col]):\n",
        "                max_value, min_value = df[col].max(), df[col].min()\n",
        "            pg_type = infer_postgresql_type(df[col].dtype, max_value, min_value)\n",
        "            columns_with_types.append(f'\"{col}\" {pg_type}')\n",
        "\n",
        "        create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({', '.join(columns_with_types)});\"\n",
        "        cur.execute(create_table_query)\n",
        "        conn.commit()\n",
        "        print(f\"Tabla '{table_name}' creada exitosamente.\")\n",
        "\n",
        "        # Insertar datos en la tabla\n",
        "        data_tuples = [tuple(row) for row in df.to_numpy()]\n",
        "        cols = ', '.join([f'\"{col}\"' for col in df.columns])\n",
        "        placeholders = ', '.join(['%s'] * len(df.columns))\n",
        "        insert_query = f\"INSERT INTO {table_name} ({cols}) VALUES ({placeholders});\"\n",
        "        cur.executemany(insert_query, data_tuples)\n",
        "        conn.commit()\n",
        "        print(f\"{len(data_tuples)} registros insertados en la tabla '{table_name}'.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo {file_path}: {e}\")\n",
        "    finally:\n",
        "        if cur:\n",
        "            cur.close()\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "# Leer el directorio y procesar archivos que comiencen con \"tickets\"\n",
        "for filename in os.listdir(local_folder):\n",
        "    if filename.startswith(\"tickets\"):  # Verifica si el archivo comienza con \"tickets\"\n",
        "        file_path = os.path.join(local_folder, filename)\n",
        "        process_file(file_path)\n"
      ],
      "metadata": {
        "id": "HoBZutIph2Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psycopg2\n",
        "import pandas as pd\n",
        "\n",
        "# Configuración de conexión a PostgreSQL\n",
        "db_host = os.getenv(\"DB_HOST\", \"localhost\")\n",
        "db_name = os.getenv(\"DB_NAME\", \"spaceman\")\n",
        "db_user = os.getenv(\"DB_USER\", \"postgres\")\n",
        "db_password = os.getenv(\"DB_PASSWORD\", \"dba\")\n",
        "db_port = os.getenv(\"DB_PORT\", \"5432\")\n",
        "\n",
        "# Ruta local donde se encuentran los archivos\n",
        "local_folder = r\"C:\\Users\\dsantander\\Downloads\\Spaceman\"\n",
        "\n",
        "# Inferir el tipo de datos de PostgreSQL basado en pandas\n",
        "def infer_postgresql_type(dtype, max_value=None, min_value=None):\n",
        "    if pd.api.types.is_integer_dtype(dtype):\n",
        "        if max_value and (max_value > 2_147_483_647 or min_value < -2_147_483_648):\n",
        "            return \"BIGINT\"\n",
        "        return \"INTEGER\"\n",
        "    elif pd.api.types.is_float_dtype(dtype):\n",
        "        return \"REAL\"\n",
        "    elif pd.api.types.is_bool_dtype(dtype):\n",
        "        return \"BOOLEAN\"\n",
        "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
        "        return \"TIMESTAMP\"\n",
        "    else:\n",
        "        return \"TEXT\"\n",
        "\n",
        "# Crear tabla e insertar registros en PostgreSQL\n",
        "def process_file(file_path, delimiter=\";\"):\n",
        "    conn = None\n",
        "    cur = None\n",
        "    try:\n",
        "        # Conexión a la base de datos\n",
        "        conn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password, port=db_port)\n",
        "        cur = conn.cursor()\n",
        "\n",
        "        # Leer el archivo con pandas, probando diferentes codificaciones\n",
        "        encodings_to_try = ['utf-8', 'latin-1', 'ISO-8859-1']\n",
        "        df = None\n",
        "        for encoding in encodings_to_try:\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, delimiter=delimiter, low_memory=False, on_bad_lines='skip', encoding=encoding)\n",
        "                break  # Si se lee correctamente, salimos del bucle\n",
        "            except UnicodeDecodeError:\n",
        "                continue  # Intenta con la siguiente codificación\n",
        "\n",
        "        if df is None:\n",
        "            print(f\"No se pudo leer el archivo {file_path} con las codificaciones probadas.\")\n",
        "            return\n",
        "\n",
        "        # Validar que el DataFrame no esté vacío\n",
        "        if df.empty:\n",
        "            print(f\"El archivo {file_path} está vacío o no tiene datos válidos.\")\n",
        "            return\n",
        "\n",
        "        # Inferir tipos de columnas y construir la sentencia CREATE TABLE\n",
        "        table_name = \"productos\"  # Nombre de la tabla basada en el nombre requerido\n",
        "        columns_with_types = []\n",
        "        for col in df.columns:\n",
        "            max_value, min_value = None, None\n",
        "            if pd.api.types.is_numeric_dtype(df[col]):\n",
        "                max_value, min_value = df[col].max(), df[col].min()\n",
        "            pg_type = infer_postgresql_type(df[col].dtype, max_value, min_value)\n",
        "            columns_with_types.append(f'\"{col}\" {pg_type}')\n",
        "\n",
        "        create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({', '.join(columns_with_types)});\"\n",
        "        cur.execute(create_table_query)\n",
        "        conn.commit()\n",
        "        print(f\"Tabla '{table_name}' creada exitosamente.\")\n",
        "\n",
        "        # Insertar datos en la tabla\n",
        "        data_tuples = [tuple(row) for row in df.to_numpy()]\n",
        "        cols = ', '.join([f'\"{col}\"' for col in df.columns])\n",
        "        placeholders = ', '.join(['%s'] * len(df.columns))\n",
        "        insert_query = f\"INSERT INTO {table_name} ({cols}) VALUES ({placeholders});\"\n",
        "        cur.executemany(insert_query, data_tuples)\n",
        "        conn.commit()\n",
        "        print(f\"{len(data_tuples)} registros insertados en la tabla '{table_name}'.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar el archivo {file_path}: {e}\")\n",
        "    finally:\n",
        "        if cur:\n",
        "            cur.close()\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "# Leer el directorio y procesar archivos que comiencen con \"tickets\"\n",
        "for filename in os.listdir(local_folder):\n",
        "    if filename.startswith(\"productos\"):  # Verifica si el archivo comienza con \"tickets\"\n",
        "        file_path = os.path.join(local_folder, filename)\n",
        "        process_file(file_path)"
      ],
      "metadata": {
        "id": "OCecyHnOh3ZL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}